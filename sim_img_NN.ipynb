{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read back in data set\n",
    "f1 = h5py.File('sim_tl_data.hdf5', 'r')\n",
    "\n",
    "train_images1 = f1[\"images\"]\n",
    "labels1 = f1[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change to numpy arrays so keras can use\n",
    "train_images1 = np.array(train_images1)\n",
    "labels1 = np.array(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read back in data set\n",
    "f2 = h5py.File('bosch_tl_data_color.hdf5', 'r')\n",
    "\n",
    "train_images2 = f2[\"images\"]\n",
    "labels2 = f2[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to numpy arrays so keras can use\n",
    "train_images2 = np.array(train_images2)\n",
    "labels2 = np.array(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images = np.concatenate((train_images1, train_images2))\n",
    "labels = np.concatenate((labels1, labels2))\n",
    "\n",
    "train_images1 = 0\n",
    "train_images2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking distribution\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(labels, bins = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IF GRAYSCALE ONLY\n",
    "#train_images = train_images[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "labels = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary items from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n",
    "batch_size = 30\n",
    "epochs = 20\n",
    "pool_size = (2, 2)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is the actual neural network\n",
    "model = Sequential()\n",
    "# Normalizes incoming inputs. First layer needs the input shape to work\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(32, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(16, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(Conv2D(8, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Flatten and Dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# FC Layer 1\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# FC Layer 2\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Final FC Layer - five classes\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Using a generator to help the model generalize/train better\n",
    "datagen = ImageDataGenerator(rotation_range = 20, horizontal_flip = True, vertical_flip = False, \n",
    "                             channel_shift_range = 0.2, zoom_range = 0.2, width_shift_range = 0.2, \n",
    "                             height_shift_range = 0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Compiling and training the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), samples_per_epoch = len(X_train), nb_epoch=epochs, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model architecture and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
